{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playful project\n",
    "This project is about forecasting the next 5 days air temperature. In addition, 4 types of predictions and their comparison will be used, which include\n",
    "1- use of API from <https://api.weatherapi.com>\n",
    "2- users prediction (guess of next 5 days temperature)\n",
    "3- model prediction based on 2 dataset from <https://www.knmi.nl/>\n",
    "4- calculate the historical averages for the same day and month across years for the next five days\n",
    "\n",
    "Moreover, the result of this project are:\n",
    "1- by comparing API's prediction, historical Average Temperature and model prediction can be evaluated \n",
    "2- Users can know how accurate their forecast is, and this program will give them suggestions based on the temperature in the output, in addition to showing the accuracy of their forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technology\n",
    "Predictive Analytics: AI-powered predictive analytics models will analyze historical air temperature data to forecast future air temperature patterns. This predictive capability will enable system and users to know about the accuracy of their prediction (Eichholtz, 2021; He et al., 2022).\n",
    "\n",
    "## ML Model Implementation \n",
    "\n",
    "The proposed solution will employ various ML models to achieve its goals, including: \n",
    "//Regression Models and Neural Network: will be used to predict future air temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Two datase from KNMI.nl will be used. \n",
    "\n",
    "1- monthly air temperature avarage between 1981 to 2024\n",
    "\n",
    "2- daily avarage air temperature between 1981 to 2011 \n",
    "\n",
    "and API data from api.weatherapi.com\n",
    "\n",
    "For predicting the next five days' air temperatures, it would be most relevant to use the daily temperature dataset, as it provides the granularity needed for daily predictions. While the yearly data could provide some long-term trends and seasonality insights, the daily dataset will be more directly applicable for short-term forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 1 : predict based on historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the seaborn and matplotlib.pyplot libraries along with pandas. \n",
    "# These libraries are commonly used for data visualization in Python\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(            station 1  station 2  station 3  station 4  station 5  station 6  \\\n",
       " date                                                                           \n",
       " 1981-01-01        6.6        5.4        5.7        5.2        5.0        3.7   \n",
       " 1981-01-02        7.7        7.5        7.5        7.5        7.6        6.6   \n",
       " 1981-01-03        8.7        8.1        8.3        9.0        8.3        7.9   \n",
       " 1981-01-04        5.6        5.1        5.2        4.6        5.0        3.7   \n",
       " 1981-01-05        4.6        3.8        3.4        3.0        3.4        1.9   \n",
       " \n",
       "             station 7  station 8  station 9  station 10  station 11  \\\n",
       " date                                                                  \n",
       " 1981-01-01        4.2        4.3        7.2         6.1         5.5   \n",
       " 1981-01-02        6.8        6.4        7.5         7.9         7.2   \n",
       " 1981-01-03        7.9        8.3        8.7         9.1         8.9   \n",
       " 1981-01-04        4.4        3.9        6.1         5.1         4.4   \n",
       " 1981-01-05        2.4        2.0        4.8         3.7         2.9   \n",
       " \n",
       "             station 12  station 13  station 14  daily average  \n",
       " date                                                           \n",
       " 1981-01-01         5.4         5.2         5.7            5.3  \n",
       " 1981-01-02         7.1         7.2         6.4            7.3  \n",
       " 1981-01-03         9.0         9.1         8.4            8.6  \n",
       " 1981-01-04         4.2         4.2         4.1            4.7  \n",
       " 1981-01-05         2.8         2.8         2.4            3.2  ,\n",
       " station 1        0\n",
       " station 2        0\n",
       " station 3        0\n",
       " station 4        0\n",
       " station 5        0\n",
       " station 6        0\n",
       " station 7        0\n",
       " station 8        0\n",
       " station 9        0\n",
       " station 10       0\n",
       " station 11       0\n",
       " station 12       0\n",
       " station 13       0\n",
       " station 14       0\n",
       " daily average    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset\n",
    "daily_temp_df = pd.read_csv('daily_temp1_1981_2011_one_decimal.csv')\n",
    "\n",
    "# Convert the 'years' column to a datetime format for easier manipulation\n",
    "daily_temp_df['date'] = pd.to_datetime(daily_temp_df['years'], format='%Y%m%d')\n",
    "\n",
    "# Drop the original 'years' column as it's no longer needed\n",
    "daily_temp_df.drop('years', axis=1, inplace=True)\n",
    "\n",
    "# Set the 'date' column as the index of the dataframe\n",
    "daily_temp_df.set_index('date', inplace=True)\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "missing_values = daily_temp_df.isnull().sum()\n",
    "\n",
    "# Display the first few rows and missing values count for review\n",
    "(daily_temp_df.head(), missing_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/hv48bjw10wjdrwbqkf_f79980000gn/T/ipykernel_15095/1899146636.py:19: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  daily_temp_df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station 1</th>\n",
       "      <th>station 2</th>\n",
       "      <th>station 3</th>\n",
       "      <th>station 4</th>\n",
       "      <th>station 5</th>\n",
       "      <th>station 6</th>\n",
       "      <th>station 7</th>\n",
       "      <th>station 8</th>\n",
       "      <th>station 9</th>\n",
       "      <th>station 10</th>\n",
       "      <th>...</th>\n",
       "      <th>station 14</th>\n",
       "      <th>daily average</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>temp_lag_1</th>\n",
       "      <th>temp_lag_2</th>\n",
       "      <th>temp_lag_3</th>\n",
       "      <th>temp_lag_4</th>\n",
       "      <th>temp_lag_5</th>\n",
       "      <th>rolling_avg_7d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-01</th>\n",
       "      <td>6.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-02</th>\n",
       "      <td>7.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-03</th>\n",
       "      <td>8.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-04</th>\n",
       "      <td>5.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-01-05</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            station 1  station 2  station 3  station 4  station 5  station 6  \\\n",
       "date                                                                           \n",
       "1981-01-01        6.6        5.4        5.7        5.2        5.0        3.7   \n",
       "1981-01-02        7.7        7.5        7.5        7.5        7.6        6.6   \n",
       "1981-01-03        8.7        8.1        8.3        9.0        8.3        7.9   \n",
       "1981-01-04        5.6        5.1        5.2        4.6        5.0        3.7   \n",
       "1981-01-05        4.6        3.8        3.4        3.0        3.4        1.9   \n",
       "\n",
       "            station 7  station 8  station 9  station 10  ...  station 14  \\\n",
       "date                                                     ...               \n",
       "1981-01-01        4.2        4.3        7.2         6.1  ...         5.7   \n",
       "1981-01-02        6.8        6.4        7.5         7.9  ...         6.4   \n",
       "1981-01-03        7.9        8.3        8.7         9.1  ...         8.4   \n",
       "1981-01-04        4.4        3.9        6.1         5.1  ...         4.1   \n",
       "1981-01-05        2.4        2.0        4.8         3.7  ...         2.4   \n",
       "\n",
       "            daily average  day_of_year  day_of_week  temp_lag_1  temp_lag_2  \\\n",
       "date                                                                          \n",
       "1981-01-01            5.3            1            3         5.3         5.3   \n",
       "1981-01-02            7.3            2            4         5.3         5.3   \n",
       "1981-01-03            8.6            3            5         7.3         5.3   \n",
       "1981-01-04            4.7            4            6         8.6         7.3   \n",
       "1981-01-05            3.2            5            0         4.7         8.6   \n",
       "\n",
       "            temp_lag_3  temp_lag_4  temp_lag_5  rolling_avg_7d  \n",
       "date                                                            \n",
       "1981-01-01         5.3         5.3         5.3             4.5  \n",
       "1981-01-02         5.3         5.3         5.3             4.5  \n",
       "1981-01-03         5.3         5.3         5.3             4.5  \n",
       "1981-01-04         5.3         5.3         5.3             4.5  \n",
       "1981-01-05         7.3         5.3         5.3             4.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuing from the corrected preprocessing step, let's perform feature engineering on the correct dataframe variable `daily_temp_df`.\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# Day of the year and day of the week to capture seasonal and weekly effects\n",
    "daily_temp_df['day_of_year'] = daily_temp_df.index.dayofyear\n",
    "daily_temp_df['day_of_week'] = daily_temp_df.index.dayofweek\n",
    "\n",
    "# Lag features - temperatures from previous days to capture recent trends\n",
    "num_lags = 5  # Number of lag days\n",
    "for lag in range(1, num_lags + 1):\n",
    "    daily_temp_df[f'temp_lag_{lag}'] = daily_temp_df['daily average'].shift(lag)\n",
    "\n",
    "# Rolling average - to smooth out short-term fluctuations and highlight longer-term trends\n",
    "rolling_window_size = 7  # 7-day rolling window\n",
    "daily_temp_df['rolling_avg_7d'] = daily_temp_df['daily average'].rolling(window=rolling_window_size).mean()\n",
    "\n",
    "# Fill any NaN values created by the lag and rolling features with backward fill\n",
    "daily_temp_df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Display the updated dataframe to verify the new features\n",
    "daily_temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10410, 22), (547, 22), (10410,), (547,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Splitting the Data\n",
    "\n",
    "# For time series forecasting, especially when we're predicting the next 5 days,\n",
    "# we typically use the most recent data for testing and the rest for training.\n",
    "# However, as per your requirement, since we're predicting future values beyond the available dataset,\n",
    "# we will consider the last part of the dataset for validation (not exactly future but unseen during training).\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target variable\n",
    "X = daily_temp_df.drop(columns=['daily average'])  # All other columns are features\n",
    "y = daily_temp_df['daily average']  # Target variable\n",
    "\n",
    "# Since this is time-series data, we won't shuffle the rows randomly.\n",
    "# Let's take the last 5% of data for testing which simulates predicting future temperatures.\n",
    "test_size = int(len(X) * 0.05)  # Adjust the test size if needed\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "\n",
    "# Verify the sizes of the datasets\n",
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modeling - Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1506255208521871, 0.10553564899451548)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Modeling - Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # adjust these parameters\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "\n",
    "# Output the performance metrics for the Random Forest model\n",
    "(rmse_rf, mae_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Modeling - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14389893243012583, 0.11980014209589204)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Modeling - Neural Network\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize the MLPRegressor (Neural Network)\n",
    "# This is a basic neural network setup; parameters can be adjusted for optimization\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_test, y_pred_nn))\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "\n",
    "# Output the performance metrics for the Neural Network model\n",
    "(rmse_nn, mae_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict the next five days' temperatures based on the Random Forest and Neural Network models i've trained, i would ideally require the recent actual data to update my lag features. Since i don't have future data, I'll illustrate how I can use the last part of my training data to create a simplified version of \"future data\". Remember, this is a makeshift approach due to the absence of real future data:\n",
    "\n",
    "Firstly, ensure that my models and the necessary Python packages are correctly set up as per my previous code. Then, let's craft the future_data using the latest available information from my training set (X_train). This involves shifting lagged temperature values to simulate \"future\" inputs based on the last known data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/iam/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next 5 days' temperature predictions:\n",
      "--------------------------------------\n",
      "Day | Random Forest | Neural Network\n",
      "--------------------------------------\n",
      "Day 1 | 24.21°C        | 24.25°C\n",
      "Day 2 | 24.21°C        | 24.25°C\n",
      "Day 3 | 24.21°C        | 24.25°C\n",
      "Day 4 | 24.21°C        | 24.25°C\n",
      "Day 5 | 24.21°C        | 24.25°C\n"
     ]
    }
   ],
   "source": [
    "# Create future_data based on the last 5 days from the training data\n",
    "# For simplicity, let's replicate the last day data and shift lag features assuming stable conditions\n",
    "# Note: This is a simplification. Normally, I should update this based on actual recent weather data.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the 'future_data' for the next 5 days based on the shifted values of the last day in the training set\n",
    "future_data_list = []\n",
    "for i in range(1, 6):  # Create data for the next 5 days\n",
    "    new_row = X_train.iloc[-1].copy()  # Start with the last day in training data\n",
    "    # Shift temperature lags; in real scenario, update this with actual temperature forecasts or measurements\n",
    "    for lag in range(1, 6):  # Assuming I have 5 lags\n",
    "        if lag == 1:  # For the first lag, it's the last known value\n",
    "            new_row[f'temp_lag_{lag}'] = y_train.iloc[-1]  # Last known actual temperature\n",
    "        else:  # For other lags, shift the previous lags\n",
    "            new_row[f'temp_lag_{lag}'] = X_train.iloc[-1][f'temp_lag_{lag - 1}']\n",
    "    future_data_list.append(new_row)\n",
    "\n",
    "# Convert the list of future data rows into a DataFrame\n",
    "future_data = pd.DataFrame(future_data_list)\n",
    "\n",
    "# Predict the next 5 days with both models\n",
    "future_pred_rf = rf_model.predict(future_data)\n",
    "future_pred_nn = nn_model.predict(future_data)\n",
    "\n",
    "# Display the predictions\n",
    "print(\"Next 5 days' temperature predictions:\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"Day | Random Forest | Neural Network\")\n",
    "print(\"--------------------------------------\")\n",
    "for day in range(5):\n",
    "    print(f\"Day {day + 1} | {future_pred_rf[day]:.2f}°C        | {future_pred_nn[day]:.2f}°C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution 2 : predict based on API from <https://api.weatherapi.com>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Daily Temperatures for the Next 5 Days in Gouda, Netherlands:\n",
      "--------------------------------------------------------------\n",
      "Date: 2024-03-09, Average Temp: 9.20°C\n",
      "Date: 2024-03-10, Average Temp: 8.90°C\n",
      "Date: 2024-03-11, Average Temp: 7.85°C\n",
      "Date: 2024-03-12, Average Temp: 6.80°C\n",
      "Date: 2024-03-13, Average Temp: 7.05°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Actual WeatherAPI key\n",
    "api_key = \"20dda7b73ea54e7f8d5122008240303\"\n",
    "location = \"Gouda, Netherlands\"  # The location for which I want the forecast\n",
    "url = f\"http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={location}&days=5&aqi=no&alerts=no\"\n",
    "\n",
    "# Send the request to WeatherAPI\n",
    "response = requests.get(url)\n",
    "forecast_data = response.json()  # Convert the response to JSON format\n",
    "\n",
    "# Now, let's extract, calculate, and print the average temperature for each of the next 5 days\n",
    "print(f\"Average Daily Temperatures for the Next 5 Days in {location}:\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "for day in forecast_data['forecast']['forecastday']:\n",
    "    date = day['date']\n",
    "    max_temp = day['day']['maxtemp_c']\n",
    "    min_temp = day['day']['mintemp_c']\n",
    "    avg_temp = (max_temp + min_temp) / 2  # Calculate the daily average temperature\n",
    "    print(f\"Date: {date}, Average Temp: {avg_temp:.2f}°C\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* how each source compares for the upcoming five days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 5-day temperature forecasts:\n",
      "---------------------------------------\n",
      "Day | API Avg Temp | Random Forest | Neural Network\n",
      "---------------------------------------\n",
      "Day 1 | 9.20°C        | 24.21°C        | 24.25°C\n",
      "Day 2 | 8.90°C        | 24.21°C        | 24.25°C\n",
      "Day 3 | 7.85°C        | 24.21°C        | 24.25°C\n",
      "Day 4 | 6.80°C        | 24.21°C        | 24.25°C\n",
      "Day 5 | 7.05°C        | 24.21°C        | 24.25°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fetch the forecast from WeatherAPI\n",
    "api_key = \"20dda7b73ea54e7f8d5122008240303\"  # Replace with your actual WeatherAPI key\n",
    "location = \"Gouda, Netherlands\"\n",
    "url = f\"http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={location}&days=5&aqi=no&alerts=no\"\n",
    "response = requests.get(url)\n",
    "forecast_data = response.json()  # Convert response to JSON\n",
    "\n",
    "# Extract average forecast temperatures from the API data\n",
    "api_forecast_temps = [(day['day']['maxtemp_c'] + day['day']['mintemp_c']) / 2 for day in forecast_data['forecast']['forecastday']]\n",
    "\n",
    "# Compare with your models' predictions\n",
    "print(\"Comparing 5-day temperature forecasts:\")\n",
    "print(\"---------------------------------------\")\n",
    "print(\"Day | API Avg Temp | Random Forest | Neural Network\")\n",
    "print(\"---------------------------------------\")\n",
    "for day in range(5):\n",
    "    print(f\"Day {day + 1} | {api_forecast_temps[day]:.2f}°C        | {future_pred_rf[day]:.2f}°C        | {future_pred_nn[day]:.2f}°C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* calculate the historical averages for the same day and month across years for the next five days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure 'daily_temp_df' is indexed by date if it's not already\n",
    "if not isinstance(daily_temp_df.index, pd.DatetimeIndex):\n",
    "    daily_temp_df['date'] = pd.to_datetime(daily_temp_df['years'], format='%Y%m%d')  # Adjust format as necessary\n",
    "    daily_temp_df.set_index('date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-03-09: Historical Average Temperature: 6.44°C\n",
      "Date: 2024-03-10: Historical Average Temperature: 6.76°C\n",
      "Date: 2024-03-11: Historical Average Temperature: 6.72°C\n",
      "Date: 2024-03-12: Historical Average Temperature: 6.54°C\n",
      "Date: 2024-03-13: Historical Average Temperature: 6.50°C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Correcting the dataframe filtering logic\n",
    "for i in range(5):\n",
    "    target_date = today + timedelta(days=i)\n",
    "    # Make sure to group the conditions with parentheses\n",
    "    same_day = daily_temp_df[(daily_temp_df.index.month == target_date.month) & (daily_temp_df.index.day == target_date.day)]\n",
    "    # Calculate the average of daily average temperatures for this date\n",
    "    historical_avg = same_day['daily average'].mean()\n",
    "    print(f\"Date: {target_date.strftime('%Y-%m-%d')}: Historical Average Temperature: {historical_avg:.2f}°C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This script first fetches the forecast from WeatherAPI, calculates the historical average temperatures for the same dates over the years from my dataset, and then prints a comparison table that includes the API's forecast, my Random Forest and Neural Network predictions, and the historical averages. This will provide a comprehensive view, showing how each source compares for the upcoming five days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 5-day temperature forecasts:\n",
      "---------------------------------------------------------------\n",
      "Day | API Avg Temp | Random Forest | Neural Network | Historical Avg\n",
      "---------------------------------------------------------------\n",
      "Day 1 | 9.20°C        | 24.21°C        | 24.25°C        | 6.44°C\n",
      "Day 2 | 8.90°C        | 24.21°C        | 24.25°C        | 6.76°C\n",
      "Day 3 | 7.85°C        | 24.21°C        | 24.25°C        | 6.72°C\n",
      "Day 4 | 6.80°C        | 24.21°C        | 24.25°C        | 6.54°C\n",
      "Day 5 | 7.05°C        | 24.21°C        | 24.25°C        | 6.50°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Assuming daily_temp_df is my historical data DataFrame and it's already loaded and indexed by date\n",
    "# Actual WeatherAPI key\n",
    "api_key = \"20dda7b73ea54e7f8d5122008240303\"\n",
    "location = \"Gouda, Netherlands\"\n",
    "url = f\"http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={location}&days=5&aqi=no&alerts=no\"\n",
    "response = requests.get(url)\n",
    "forecast_data = response.json()  # Convert response to JSON\n",
    "\n",
    "# Extract average forecast temperatures from the API data\n",
    "api_forecast_temps = [(day['day']['maxtemp_c'] + day['day']['mintemp_c']) / 2 for day in forecast_data['forecast']['forecastday']]\n",
    "\n",
    "# Prepare for historical average calculation\n",
    "today = datetime.now()\n",
    "historical_averages = []\n",
    "\n",
    "for i in range(5):\n",
    "    target_date = today + timedelta(days=i)\n",
    "    same_day = daily_temp_df[(daily_temp_df.index.month == target_date.month) & (daily_temp_df.index.day == target_date.day)]\n",
    "    historical_avg = same_day['daily average'].mean()\n",
    "    historical_averages.append(historical_avg)\n",
    "\n",
    "# Display comparison\n",
    "print(\"Comparing 5-day temperature forecasts:\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(\"Day | API Avg Temp | Random Forest | Neural Network | Historical Avg\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "for day in range(5):\n",
    "    print(f\"Day {day + 1} | {api_forecast_temps[day]:.2f}°C        | {future_pred_rf[day]:.2f}°C        | {future_pred_nn[day]:.2f}°C        | {historical_averages[day]:.2f}°C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The significant difference observed between the machine learning model predictions (Random Forest and Neural Network) and the WeatherAPI and historical averages could be due to several factors:\n",
    "\n",
    "* Data Discrepancy: The models were trained on historical data that may not accurately reflect current weather conditions or trends due to climate change or other factors.\n",
    "\n",
    "* Model Complexity and Overfitting: The models may be overfitted to the historical training data, capturing noise rather than the underlying patterns, thus failing to generalize to current conditions.\n",
    "\n",
    "* Inadequate Features: The models might be missing critical features that influence temperature, such as atmospheric pressure, humidity, or specific seasonal indicators, limiting their prediction accuracy.\n",
    "\n",
    "* Model Parameters: The hyperparameters for the Random Forest and Neural Network might not be optimally tuned for the best predictive performance.\n",
    "\n",
    "To improve the model predictions, consider reassessing the training data for relevance and accuracy, enhancing the feature set, evaluating model performance more rigorously, and tuning model parameters. Comparing model outputs with established meteorological predictions can also provide valuable benchmarks for model accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare user prediction and API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* integrate user predictions and compare them with the API predictions, and then provide weather-related tips based on the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ask the user for their temperature predictions for the next five days, compare these predictions with those from the WeatherAPI, and then offer advice based on whether the weather is expected to be cold or hot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing your predictions with actual forecasts:\n",
      "--------------------------------------------------\n",
      "Day | Your Prediction | API Forecast | Tips\n",
      "--------------------------------------------------\n",
      "Day 1 | 9.00°C            | 9.20°C       | It's a typical day, enjoy!\n",
      "Day 2 | 6.00°C            | 8.90°C       | It's a typical day, enjoy!\n",
      "Day 3 | 7.00°C            | 7.85°C       | It's a typical day, enjoy!\n",
      "Day 4 | 8.00°C            | 6.80°C       | It's a typical day, enjoy!\n",
      "Day 5 | 9.00°C            | 7.05°C       | It's a typical day, enjoy!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Assuming API and location setup\n",
    "api_key = \"20dda7b73ea54e7f8d5122008240303\"  # Actual API key\n",
    "location = \"Gouda, Netherlands\"\n",
    "url = f\"http://api.weatherapi.com/v1/forecast.json?key={api_key}&q={location}&days=5&aqi=no&alerts=no\"\n",
    "response = requests.get(url)\n",
    "forecast_data = response.json()\n",
    "\n",
    "# Collect user's temperature predictions\n",
    "user_predictions = []\n",
    "for i in range(1, 6):\n",
    "    temp = float(input(f\"Enter your prediction for Day {i} average temperature (°C): \"))\n",
    "    user_predictions.append(temp)\n",
    "\n",
    "# Fetch API forecast temperatures\n",
    "api_forecast_temps = [(day['day']['maxtemp_c'] + day['day']['mintemp_c']) / 2 for day in forecast_data['forecast']['forecastday']]\n",
    "\n",
    "# Compare and give tips\n",
    "print(\"\\nComparing your predictions with actual forecasts:\")\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Day | Your Prediction | API Forecast | Tips\")\n",
    "print(\"--------------------------------------------------\")\n",
    "for i, (user_pred, api_pred) in enumerate(zip(user_predictions, api_forecast_temps), start=1):\n",
    "    # Determine if it's cold or hot for simplistic tips\n",
    "    tips = \"It's a typical day, enjoy!\"\n",
    "    if api_pred < 5:\n",
    "        tips = \"The weather is cold, don't forget to wear a jacket!\"\n",
    "    elif api_pred > 25:\n",
    "        tips = \"The weather is hot, remember to stay hydrated and wear light clothing!\"\n",
    "    \n",
    "    print(f\"Day {i} | {user_pred:.2f}°C            | {api_pred:.2f}°C       | {tips}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
